{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "#import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "def starttimer():\n",
    "    start = datetime.now()\n",
    "    print(f'{start.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    return start\n",
    "\n",
    "def endtimer(start):\n",
    "    end = datetime.now()\n",
    "    print(f'{end.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "    durn = end - start\n",
    "    print(f'Duration: {durn.total_seconds()}s')\n",
    "    return end, durn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Self-Attention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor \n",
      " [[0.1 0.2 0.9]\n",
      " [0.5 0.3 0.8]\n",
      " [0.6 0.4 0.8]]\n",
      "-------------------------------------------------\n",
      "Q \n",
      " [0.1 0.2 0.9 0.5 0.3 0.8 0.6 0.4 0.8]\n",
      "-------------------------------------------------\n",
      "K \n",
      " [0.1 0.2 0.9 0.5 0.3 0.8 0.6 0.4 0.8]\n",
      "-------------------------------------------------\n",
      "V \n",
      " [0.1 0.2 0.9 0.5 0.3 0.8 0.6 0.4 0.8]\n",
      "-------------------------------------------------\n",
      "Kt \n",
      " [[0.1]\n",
      " [0.2]\n",
      " [0.9]\n",
      " [0.5]\n",
      " [0.3]\n",
      " [0.8]\n",
      " [0.6]\n",
      " [0.4]\n",
      " [0.8]]\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.Tensor([[0.1, 0.2, 0.9],\n",
    "                             [0.5, 0.3, 0.8],\n",
    "                             [0.6, 0.4, 0.8]])\n",
    "\n",
    "print(f'input_tensor \\n {input_tensor.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "\n",
    "# in Self-Attention, Q=K=V\n",
    "# create vectors for Q,K,V and K transposed\n",
    "Q = K = V = torch.flatten(input=input_tensor)\n",
    "Kt = K.reshape(-1,1)\n",
    "print(f'Q \\n {Q.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'K \\n {K.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'V \\n {V.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'Kt \\n {Kt.numpy()}', end='\\n-------------------------------------------------\\n')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q*Kt \n",
      " tensor([[0.0100, 0.0200, 0.0900, 0.0500, 0.0300, 0.0800, 0.0600, 0.0400, 0.0800],\n",
      "        [0.0200, 0.0400, 0.1800, 0.1000, 0.0600, 0.1600, 0.1200, 0.0800, 0.1600],\n",
      "        [0.0900, 0.1800, 0.8100, 0.4500, 0.2700, 0.7200, 0.5400, 0.3600, 0.7200],\n",
      "        [0.0500, 0.1000, 0.4500, 0.2500, 0.1500, 0.4000, 0.3000, 0.2000, 0.4000],\n",
      "        [0.0300, 0.0600, 0.2700, 0.1500, 0.0900, 0.2400, 0.1800, 0.1200, 0.2400],\n",
      "        [0.0800, 0.1600, 0.7200, 0.4000, 0.2400, 0.6400, 0.4800, 0.3200, 0.6400],\n",
      "        [0.0600, 0.1200, 0.5400, 0.3000, 0.1800, 0.4800, 0.3600, 0.2400, 0.4800],\n",
      "        [0.0400, 0.0800, 0.3600, 0.2000, 0.1200, 0.3200, 0.2400, 0.1600, 0.3200],\n",
      "        [0.0800, 0.1600, 0.7200, 0.4000, 0.2400, 0.6400, 0.4800, 0.3200, 0.6400]])\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate Q.K(transposed) and A\n",
    "QdotKt = torch.zeros(1,1)\n",
    "QdotKt=Q*Kt\n",
    "print(f'Q*Kt \\n {QdotKt}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \n",
      " tensor([[0.1066, 0.1022, 0.0746, 0.0897, 0.0979, 0.0782, 0.0857, 0.0937, 0.0782],\n",
      "        [0.1077, 0.1043, 0.0816, 0.0943, 0.1009, 0.0847, 0.0910, 0.0975, 0.0847],\n",
      "        [0.1155, 0.1199, 0.1532, 0.1338, 0.1245, 0.1482, 0.1385, 0.1291, 0.1482],\n",
      "        [0.1109, 0.1107, 0.1069, 0.1095, 0.1104, 0.1076, 0.1090, 0.1100, 0.1076],\n",
      "        [0.1088, 0.1064, 0.0893, 0.0991, 0.1040, 0.0917, 0.0966, 0.1015, 0.0917],\n",
      "        [0.1143, 0.1176, 0.1400, 0.1272, 0.1208, 0.1368, 0.1304, 0.1240, 0.1368],\n",
      "        [0.1121, 0.1129, 0.1169, 0.1151, 0.1137, 0.1166, 0.1157, 0.1145, 0.1166],\n",
      "        [0.1098, 0.1085, 0.0977, 0.1042, 0.1071, 0.0994, 0.1026, 0.1057, 0.0994],\n",
      "        [0.1143, 0.1176, 0.1400, 0.1272, 0.1208, 0.1368, 0.1304, 0.1240, 0.1368]])\n",
      "-------------------------------------------------\n",
      "sum(A) \n",
      " 9.0\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate Softmax of Q.Kt\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "A = softmax(QdotKt)\n",
    "print(f'A \\n {A}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'sum(A) \\n {A.sum()}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV \n",
      " tensor([0.3864, 0.4115, 0.6495, 0.4989, 0.4386, 0.6076, 0.5325, 0.4676, 0.6076])\n",
      "-------------------------------------------------\n",
      "input_tensor \n",
      " tensor([[0.1000, 0.2000, 0.9000],\n",
      "        [0.5000, 0.3000, 0.8000],\n",
      "        [0.6000, 0.4000, 0.8000]])\n",
      "-------------------------------------------------\n",
      "output_tensor \n",
      " tensor([[0.3864, 0.4115, 0.6495],\n",
      "        [0.4989, 0.4386, 0.6076],\n",
      "        [0.5325, 0.4676, 0.6076]])\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate AV\n",
    "AV = torch.zeros(1,1)\n",
    "AV=torch.matmul(A,V)\n",
    "print(f'AV \\n {AV}', end='\\n-------------------------------------------------\\n')\n",
    "\n",
    "output_tensor = torch.reshape(AV,(3,3))\n",
    "print(f'input_tensor \\n {input_tensor}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'output_tensor \\n {output_tensor}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Calculating Cross-Attention"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor \n",
      " [[0.1 0.2 0.9]\n",
      " [0.5 0.3 0.8]\n",
      " [0.6 0.4 0.8]]\n",
      "-------------------------------------------------\n",
      "Q \n",
      " [0.1 0.2 0.9 0.5 0.3 0.8 0.6 0.4 0.8]\n",
      "-------------------------------------------------\n",
      "K \n",
      " [0.1 0.2 0.9 0.5 0.3 0.8 0.6 0.4 0.8]\n",
      "-------------------------------------------------\n",
      "V \n",
      " [0.1 0.2 0.9 0.5 0.3 0.8 0.6 0.4 0.8]\n",
      "-------------------------------------------------\n",
      "Kt \n",
      " [[0.1]\n",
      " [0.2]\n",
      " [0.9]\n",
      " [0.5]\n",
      " [0.3]\n",
      " [0.8]\n",
      " [0.6]\n",
      " [0.4]\n",
      " [0.8]]\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "feature_input = torch.Tensor([[0.1, 0.2, 0.9],\n",
    "                             [0.5, 0.3, 0.8],\n",
    "                             [0.6, 0.4, 0.8]])\n",
    "\n",
    "skip_connection = torch.Tensor([[0.8, 0.6, 0.4, 0.4, 0.8, 0.9],\n",
    "                                [0.8, 0.8, 0.7, 0.4, 0.7, 0.9],\n",
    "                                [0.7, 0.6, 0.7, 0.4, 0.4, 0.4],\n",
    "                                [0.5, 0.4, 0.2, 0.1, 0.1, 0.1],\n",
    "                                [0.1, 0.1, 0.1, 0.1, 0.1, 0.1],\n",
    "                                [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])\n",
    "\n",
    "print(f'skip_connection \\n {skip_connection.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'feature_input \\n {feature_input.numpy()}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# in Cross-Attention, Q=K feature input and V = skip connection\n",
    "# create vectors for Q,K,V and K transposed\n",
    "Q = K = V = torch.flatten(input=input_tensor)\n",
    "Kt = K.reshape(-1,1)\n",
    "print(f'Q \\n {Q.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'K \\n {K.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'V \\n {V.numpy()}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'Kt \\n {Kt.numpy()}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q*Kt \n",
      " tensor([[0.0100, 0.0200, 0.0900, 0.0500, 0.0300, 0.0800, 0.0600, 0.0400, 0.0800],\n",
      "        [0.0200, 0.0400, 0.1800, 0.1000, 0.0600, 0.1600, 0.1200, 0.0800, 0.1600],\n",
      "        [0.0900, 0.1800, 0.8100, 0.4500, 0.2700, 0.7200, 0.5400, 0.3600, 0.7200],\n",
      "        [0.0500, 0.1000, 0.4500, 0.2500, 0.1500, 0.4000, 0.3000, 0.2000, 0.4000],\n",
      "        [0.0300, 0.0600, 0.2700, 0.1500, 0.0900, 0.2400, 0.1800, 0.1200, 0.2400],\n",
      "        [0.0800, 0.1600, 0.7200, 0.4000, 0.2400, 0.6400, 0.4800, 0.3200, 0.6400],\n",
      "        [0.0600, 0.1200, 0.5400, 0.3000, 0.1800, 0.4800, 0.3600, 0.2400, 0.4800],\n",
      "        [0.0400, 0.0800, 0.3600, 0.2000, 0.1200, 0.3200, 0.2400, 0.1600, 0.3200],\n",
      "        [0.0800, 0.1600, 0.7200, 0.4000, 0.2400, 0.6400, 0.4800, 0.3200, 0.6400]])\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate Q.K(transposed) and A\n",
    "QdotKt = torch.zeros(1,1)\n",
    "QdotKt=Q*Kt\n",
    "print(f'Q*Kt \\n {QdotKt}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A \n",
      " tensor([[0.1066, 0.1022, 0.0746, 0.0897, 0.0979, 0.0782, 0.0857, 0.0937, 0.0782],\n",
      "        [0.1077, 0.1043, 0.0816, 0.0943, 0.1009, 0.0847, 0.0910, 0.0975, 0.0847],\n",
      "        [0.1155, 0.1199, 0.1532, 0.1338, 0.1245, 0.1482, 0.1385, 0.1291, 0.1482],\n",
      "        [0.1109, 0.1107, 0.1069, 0.1095, 0.1104, 0.1076, 0.1090, 0.1100, 0.1076],\n",
      "        [0.1088, 0.1064, 0.0893, 0.0991, 0.1040, 0.0917, 0.0966, 0.1015, 0.0917],\n",
      "        [0.1143, 0.1176, 0.1400, 0.1272, 0.1208, 0.1368, 0.1304, 0.1240, 0.1368],\n",
      "        [0.1121, 0.1129, 0.1169, 0.1151, 0.1137, 0.1166, 0.1157, 0.1145, 0.1166],\n",
      "        [0.1098, 0.1085, 0.0977, 0.1042, 0.1071, 0.0994, 0.1026, 0.1057, 0.0994],\n",
      "        [0.1143, 0.1176, 0.1400, 0.1272, 0.1208, 0.1368, 0.1304, 0.1240, 0.1368]])\n",
      "-------------------------------------------------\n",
      "sum(A) \n",
      " 9.0\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate Softmax of Q.Kt\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "A = softmax(QdotKt)\n",
    "print(f'A \\n {A}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'sum(A) \\n {A.sum()}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AV \n",
      " tensor([0.3864, 0.4115, 0.6495, 0.4989, 0.4386, 0.6076, 0.5325, 0.4676, 0.6076])\n",
      "-------------------------------------------------\n",
      "input_tensor \n",
      " tensor([[0.1000, 0.2000, 0.9000],\n",
      "        [0.5000, 0.3000, 0.8000],\n",
      "        [0.6000, 0.4000, 0.8000]])\n",
      "-------------------------------------------------\n",
      "output_tensor \n",
      " tensor([[0.3864, 0.4115, 0.6495],\n",
      "        [0.4989, 0.4386, 0.6076],\n",
      "        [0.5325, 0.4676, 0.6076]])\n",
      "-------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Calculate AV\n",
    "AV = torch.zeros(1,1)\n",
    "AV=torch.matmul(A,V)\n",
    "print(f'AV \\n {AV}', end='\\n-------------------------------------------------\\n')\n",
    "\n",
    "output_tensor = torch.reshape(AV,(3,3))\n",
    "print(f'input_tensor \\n {input_tensor}', end='\\n-------------------------------------------------\\n')\n",
    "print(f'output_tensor \\n {output_tensor}', end='\\n-------------------------------------------------\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}